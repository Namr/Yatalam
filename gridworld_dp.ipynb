{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b619cbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_grid_world (generic function with 2 methods)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_index(x, y, width) = ((x-1)*width) + y\n",
    "\n",
    "\n",
    "delete_action!(action_array, action) = deleteat!(action_array, findall(x->x==action,action_array))\n",
    "\n",
    "function apply_action(state, action, width)\n",
    "    if action == 'N'\n",
    "        return state - width\n",
    "    elseif action == 'S'\n",
    "        return state + width\n",
    "    elseif action == 'E'\n",
    "        return state + 1\n",
    "    elseif action == 'W'\n",
    "        return state - 1\n",
    "    elseif action == ' '\n",
    "        return state\n",
    "    else\n",
    "        println(\"invalid action $(action) taken\")\n",
    "        return 0\n",
    "    end\n",
    "end\n",
    "\n",
    "function printdelim(width)\n",
    "    for num in 1:width\n",
    "        print(\"-----\")\n",
    "    end\n",
    "    print(\"\\n\")\n",
    "end\n",
    "\n",
    "function pretty_print_grid(grid, width, height)\n",
    "    pretty_world = round.(grid, digits=1)\n",
    "    for row in 1:height\n",
    "        printdelim(width)\n",
    "        for col in 1:width\n",
    "            num = pretty_world[coord_index(row, col, width)]\n",
    "            sign(num) != -1.0 ? print(\"| $(num)\") : print(\"|$(num)\")\n",
    "        end\n",
    "        print(\"|\\n\")\n",
    "    end\n",
    "    printdelim(width)\n",
    "end\n",
    "\n",
    "function action_to_arrow(action)\n",
    "    if action == 'N'\n",
    "        return \"^\"\n",
    "    elseif action == 'S'\n",
    "        return \"v\"\n",
    "    elseif action == 'E'\n",
    "        return \">\"\n",
    "    elseif action == 'W'\n",
    "        return \"<\"\n",
    "    elseif action == ' '\n",
    "        return \"\"\n",
    "    else\n",
    "        println(\"invalid action $(action) taken\")\n",
    "        return 0\n",
    "    end\n",
    "end\n",
    "    \n",
    "function print_action_delim(width)\n",
    "    for num in 1:width\n",
    "        print(\"-----\")\n",
    "    end\n",
    "    print(\"\\n\")\n",
    "end\n",
    "\n",
    "function pretty_print_action_grid(grid, width, height)\n",
    "    for row in 1:height\n",
    "        print_action_delim(width)\n",
    "        for col in 1:width\n",
    "            arrows = join(action_to_arrow.(grid[coord_index(row, col, width)]))    \n",
    "            while length(arrows) != 4\n",
    "                arrows = \" $arrows\"\n",
    "            end\n",
    "            \n",
    "            print(\"|$(arrows)\")\n",
    "        end\n",
    "        print(\"|\\n\")\n",
    "    end\n",
    "    print_action_delim(width)\n",
    "end\n",
    "\n",
    "function make_grid_world(width, height, initial_value = -1.0)\n",
    "    # everything but terminal states are negative values\n",
    "    gridworld = [initial_value for x in 1:(width*height)]\n",
    "    gridworld[coord_index(1,1, width)] = 0.0\n",
    "    gridworld[coord_index(width, height, width)] = 0.0\n",
    "\n",
    "    # probably could be done more elagently\n",
    "    possible_actions = [['W', 'N', 'S', 'E'] for x in 1:(width*height)]\n",
    "    for row in 1:height\n",
    "        for col in 1:width\n",
    "            if col == 1\n",
    "                delete_action!(possible_actions[coord_index(col, row, width)], 'N')\n",
    "            elseif col == height\n",
    "                delete_action!(possible_actions[coord_index(col, row, width)], 'S')\n",
    "            end\n",
    "\n",
    "            if row == 1\n",
    "                delete_action!(possible_actions[coord_index(col, row, width)], 'W')\n",
    "            elseif row == width\n",
    "                 delete_action!(possible_actions[coord_index(col, row, width)], 'E')\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    #terminal states\n",
    "    possible_actions[coord_index(1,1, width)] = [' ']\n",
    "    possible_actions[coord_index(width,height, width)] = [' ']\n",
    "    \n",
    "    return gridworld, possible_actions\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e30ba70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy_iteration (generic function with 3 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# important note: generated policy is always deterministic (i.e one action per state)\n",
    "function policy_iteration(reward_function, action_space, width, height, discount=1.0, theta_v = 0.5)\n",
    "    size = length(reward_function)\n",
    "    # just pick the first possible action for the initial policy\n",
    "    extract_first(array) = length(array) > 0 ? array[1] : ' '\n",
    "    \n",
    "    policy = extract_first.(action_space)\n",
    "    value = [0.0 for x in 1:size]\n",
    "    policy_stable = false\n",
    "    num_iter = 0\n",
    "    num_internal_iter = 0\n",
    "    \n",
    "    while !policy_stable\n",
    "        # evaluate the value function given that policy\n",
    "        while true\n",
    "            delta_v = 0.0\n",
    "            for x in 1:size\n",
    "                old_v = value[x]\n",
    "                value[x] = reward_function[x] + discount * value[apply_action(x, policy[x], width)]\n",
    "                delta_v = max(delta_v, abs(old_v - value[x]))\n",
    "            end\n",
    "            delta_v < theta_v || break\n",
    "        end\n",
    "            \n",
    "        # pick better policy based on value function\n",
    "        policy_stable = true\n",
    "        for x in 1:size\n",
    "            max_val = 0.0\n",
    "            for a in action_space[x]\n",
    "                if reward_function[x] + discount * value[apply_action(x, a, width)] > value[x]\n",
    "                    policy[x] = a\n",
    "                    policy_stable = false\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        num_iter += 1\n",
    "        num_internal_iter += 1\n",
    "    end\n",
    "    println(\"converged in $num_iter policy runs and $num_internal_iter value estimation runs\")\n",
    "    println(\"Policy is:\")\n",
    "    pretty_print_action_grid(policy, width, height)\n",
    "    println(\"Value function is:\")\n",
    "    pretty_print_grid(value, width, height)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34733393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value_iteration (generic function with 4 methods)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unzip(a) = map(x->getfield.(a, x), fieldnames(eltype(a)))\n",
    "\n",
    "function value_iteration(reward_function, action_space, width, height, discount=1.0, theta_v=0.5)\n",
    "    size = length(reward_function)\n",
    "    value = [0.0 for x in 1:size]\n",
    "    num_iter = 0\n",
    "    \n",
    "    # estimate v*\n",
    "    while true\n",
    "        delta_v = 0.0\n",
    "        for x in 1:size\n",
    "            old_v = value[x]\n",
    "            v = [reward_function[x] + discount * value[apply_action(x, a, width)] for a in action_space[x]]\n",
    "            value[x] = maximum(v)\n",
    "            delta_v = max(delta_v, abs(old_v - value[x]))\n",
    "        end\n",
    "        num_iter += 1\n",
    "        if delta_v < theta_v\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # extract policy from v*\n",
    "    policy = []\n",
    "    for x in 1:size      \n",
    "        v, a = unzip([(reward_function[x] + discount * value[apply_action(x, a, width)], a) for a in action_space[x]])\n",
    "        max_a = a[findall(x->x==maximum(v), v)[1]]\n",
    "        append!(policy, max_a)\n",
    "    end\n",
    "    \n",
    "    println(\"converged in $num_iter iterations\")\n",
    "    println(\"Policy is:\")\n",
    "    pretty_print_action_grid(policy, width, height)\n",
    "    println(\"Value function is:\")\n",
    "    pretty_print_grid(value, width, height)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84d7a88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards per state:\n",
      "--------------------\n",
      "| 0.0|-1.0|-1.0|-1.0|\n",
      "--------------------\n",
      "|-1.0|-1.0|-1.0|-1.0|\n",
      "--------------------\n",
      "|-1.0|-1.0|-1.0|-1.0|\n",
      "--------------------\n",
      "|-1.0|-1.0|-1.0| 0.0|\n",
      "--------------------\n",
      "\n",
      "possible actions per state:\n",
      "--------------------\n",
      "|    | <v>| <v>|  <v|\n",
      "--------------------\n",
      "| ^v>|<^v>|<^v>| <^v|\n",
      "--------------------\n",
      "| ^v>|<^v>|<^v>| <^v|\n",
      "--------------------\n",
      "|  ^>| <^>| <^>|    |\n",
      "--------------------\n",
      "===========================\n",
      "policy iteration solution:\n",
      "===========================\n",
      "converged in 3 policy runs and 3 value estimation runs\n",
      "Policy is:\n",
      "--------------------\n",
      "|    |   <|   <|   <|\n",
      "--------------------\n",
      "|   ^|   <|   <|   v|\n",
      "--------------------\n",
      "|   ^|   <|   >|   v|\n",
      "--------------------\n",
      "|   ^|   >|   >|    |\n",
      "--------------------\n",
      "Value function is:\n",
      "--------------------\n",
      "| 0.0|-1.0|-2.0|-3.0|\n",
      "--------------------\n",
      "|-1.0|-2.0|-3.0|-2.0|\n",
      "--------------------\n",
      "|-2.0|-3.0|-2.0|-1.0|\n",
      "--------------------\n",
      "|-3.0|-2.0|-1.0| 0.0|\n",
      "--------------------\n",
      "===========================\n",
      "value iteration solution:\n",
      "===========================\n",
      "converged in 4 iterations\n",
      "Policy is:\n",
      "--------------------\n",
      "|    |   <|   <|   <|\n",
      "--------------------\n",
      "|   ^|   <|   <|   v|\n",
      "--------------------\n",
      "|   ^|   <|   v|   v|\n",
      "--------------------\n",
      "|   ^|   >|   >|    |\n",
      "--------------------\n",
      "Value function is:\n",
      "--------------------\n",
      "| 0.0|-1.0|-2.0|-3.0|\n",
      "--------------------\n",
      "|-1.0|-2.0|-3.0|-2.0|\n",
      "--------------------\n",
      "|-2.0|-3.0|-2.0|-1.0|\n",
      "--------------------\n",
      "|-3.0|-2.0|-1.0| 0.0|\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "reward, action_space = make_grid_world(4,4)\n",
    "\n",
    "println(\"rewards per state:\")\n",
    "pretty_print_grid(reward, 4, 4)\n",
    "print(\"\\n\")\n",
    "println(\"possible actions per state:\")\n",
    "pretty_print_action_grid(action_space, 4 , 4)\n",
    "\n",
    "print(\"===========================\\n\")\n",
    "print(\"policy iteration solution:\\n\")\n",
    "print(\"===========================\\n\")\n",
    "policy_iteration(reward, action_space, 4, 4)\n",
    "\n",
    "print(\"===========================\\n\")\n",
    "print(\"value iteration solution:\\n\")\n",
    "print(\"===========================\\n\")\n",
    "value_iteration(reward, action_space, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3ad2c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards per state:\n",
      "--------------------------------------------------\n",
      "| 0.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|\n",
      "--------------------------------------------------\n",
      "|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|\n",
      "--------------------------------------------------\n",
      "|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|\n",
      "--------------------------------------------------\n",
      "|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|\n",
      "--------------------------------------------------\n",
      "|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|\n",
      "--------------------------------------------------\n",
      "|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|\n",
      "--------------------------------------------------\n",
      "|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|\n",
      "--------------------------------------------------\n",
      "|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|\n",
      "--------------------------------------------------\n",
      "|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|\n",
      "--------------------------------------------------\n",
      "|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0| 0.0|\n",
      "--------------------------------------------------\n",
      "\n",
      "possible actions per state:\n",
      "--------------------------------------------------\n",
      "|    | <v>| <v>| <v>| <v>| <v>| <v>| <v>| <v>|  <v|\n",
      "--------------------------------------------------\n",
      "| ^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>| <^v|\n",
      "--------------------------------------------------\n",
      "| ^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>| <^v|\n",
      "--------------------------------------------------\n",
      "| ^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>| <^v|\n",
      "--------------------------------------------------\n",
      "| ^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>| <^v|\n",
      "--------------------------------------------------\n",
      "| ^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>| <^v|\n",
      "--------------------------------------------------\n",
      "| ^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>| <^v|\n",
      "--------------------------------------------------\n",
      "| ^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>| <^v|\n",
      "--------------------------------------------------\n",
      "| ^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>|<^v>| <^v|\n",
      "--------------------------------------------------\n",
      "|  ^>| <^>| <^>| <^>| <^>| <^>| <^>| <^>| <^>|    |\n",
      "--------------------------------------------------\n",
      "===========================\n",
      "policy iteration solution:\n",
      "===========================\n",
      "converged in 9 policy runs and 9 value estimation runs\n",
      "Policy is:\n",
      "--------------------------------------------------\n",
      "|    |   <|   <|   <|   <|   <|   <|   <|   <|   <|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   <|   <|   <|   <|   <|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   <|   <|   <|   <|   >|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   <|   <|   <|   >|   >|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   <|   <|   >|   >|   >|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   <|   >|   >|   >|   >|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   >|   >|   >|   >|   >|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   >|   >|   >|   >|   >|   >|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   >|   >|   >|   >|   >|   >|   >|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   >|   >|   >|   >|   >|   >|   >|   >|    |\n",
      "--------------------------------------------------\n",
      "Value function is:\n",
      "--------------------------------------------------\n",
      "| 0.0|-1.0|-2.0|-3.0|-4.0|-5.0|-6.0|-7.0|-8.0|-9.0|\n",
      "--------------------------------------------------\n",
      "|-1.0|-2.0|-3.0|-4.0|-5.0|-6.0|-7.0|-8.0|-9.0|-8.0|\n",
      "--------------------------------------------------\n",
      "|-2.0|-3.0|-4.0|-5.0|-6.0|-7.0|-8.0|-9.0|-8.0|-7.0|\n",
      "--------------------------------------------------\n",
      "|-3.0|-4.0|-5.0|-6.0|-7.0|-8.0|-9.0|-8.0|-7.0|-6.0|\n",
      "--------------------------------------------------\n",
      "|-4.0|-5.0|-6.0|-7.0|-8.0|-9.0|-8.0|-7.0|-6.0|-5.0|\n",
      "--------------------------------------------------\n",
      "|-5.0|-6.0|-7.0|-8.0|-9.0|-8.0|-7.0|-6.0|-5.0|-4.0|\n",
      "--------------------------------------------------\n",
      "|-6.0|-7.0|-8.0|-9.0|-8.0|-7.0|-6.0|-5.0|-4.0|-3.0|\n",
      "--------------------------------------------------\n",
      "|-7.0|-8.0|-9.0|-8.0|-7.0|-6.0|-5.0|-4.0|-3.0|-2.0|\n",
      "--------------------------------------------------\n",
      "|-8.0|-9.0|-8.0|-7.0|-6.0|-5.0|-4.0|-3.0|-2.0|-1.0|\n",
      "--------------------------------------------------\n",
      "|-9.0|-8.0|-7.0|-6.0|-5.0|-4.0|-3.0|-2.0|-1.0| 0.0|\n",
      "--------------------------------------------------\n",
      "===========================\n",
      "value iteration solution:\n",
      "===========================\n",
      "converged in 10 iterations\n",
      "Policy is:\n",
      "--------------------------------------------------\n",
      "|    |   <|   <|   <|   <|   <|   <|   <|   <|   <|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   <|   <|   <|   <|   <|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   <|   <|   <|   <|   v|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   <|   <|   <|   v|   v|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   <|   <|   v|   v|   v|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   <|   v|   v|   v|   v|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   <|   v|   v|   v|   v|   v|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   <|   v|   v|   v|   v|   v|   v|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   <|   v|   v|   v|   v|   v|   v|   v|   v|\n",
      "--------------------------------------------------\n",
      "|   ^|   >|   >|   >|   >|   >|   >|   >|   >|    |\n",
      "--------------------------------------------------\n",
      "Value function is:\n",
      "--------------------------------------------------\n",
      "| 0.0|-1.0|-2.0|-3.0|-4.0|-5.0|-6.0|-7.0|-8.0|-9.0|\n",
      "--------------------------------------------------\n",
      "|-1.0|-2.0|-3.0|-4.0|-5.0|-6.0|-7.0|-8.0|-9.0|-8.0|\n",
      "--------------------------------------------------\n",
      "|-2.0|-3.0|-4.0|-5.0|-6.0|-7.0|-8.0|-9.0|-8.0|-7.0|\n",
      "--------------------------------------------------\n",
      "|-3.0|-4.0|-5.0|-6.0|-7.0|-8.0|-9.0|-8.0|-7.0|-6.0|\n",
      "--------------------------------------------------\n",
      "|-4.0|-5.0|-6.0|-7.0|-8.0|-9.0|-8.0|-7.0|-6.0|-5.0|\n",
      "--------------------------------------------------\n",
      "|-5.0|-6.0|-7.0|-8.0|-9.0|-8.0|-7.0|-6.0|-5.0|-4.0|\n",
      "--------------------------------------------------\n",
      "|-6.0|-7.0|-8.0|-9.0|-8.0|-7.0|-6.0|-5.0|-4.0|-3.0|\n",
      "--------------------------------------------------\n",
      "|-7.0|-8.0|-9.0|-8.0|-7.0|-6.0|-5.0|-4.0|-3.0|-2.0|\n",
      "--------------------------------------------------\n",
      "|-8.0|-9.0|-8.0|-7.0|-6.0|-5.0|-4.0|-3.0|-2.0|-1.0|\n",
      "--------------------------------------------------\n",
      "|-9.0|-8.0|-7.0|-6.0|-5.0|-4.0|-3.0|-2.0|-1.0| 0.0|\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "big_reward, big_action_space = make_grid_world(10,10)\n",
    "\n",
    "println(\"rewards per state:\")\n",
    "pretty_print_grid(big_reward, 10, 10)\n",
    "print(\"\\n\")\n",
    "println(\"possible actions per state:\")\n",
    "pretty_print_action_grid(big_action_space, 10 , 10)\n",
    "\n",
    "print(\"===========================\\n\")\n",
    "print(\"policy iteration solution:\\n\")\n",
    "print(\"===========================\\n\")\n",
    "policy_iteration(big_reward, big_action_space, 10, 10)\n",
    "\n",
    "print(\"===========================\\n\")\n",
    "print(\"value iteration solution:\\n\")\n",
    "print(\"===========================\\n\")\n",
    "value_iteration(big_reward, big_action_space, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a8e6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
